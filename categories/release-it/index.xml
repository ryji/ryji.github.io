<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Release It on Clarity</title><link>https://ryji.github.io/categories/release-it/</link><description>Recent content in Release It on Clarity</description><generator>Hugo -- gohugo.io</generator><copyright>Copyright © 2008–2018, Steve Francia and the Hugo Authors; all rights reserved.</copyright><lastBuildDate>Sat, 27 Mar 2021 10:16:33 +0800</lastBuildDate><atom:link href="https://ryji.github.io/categories/release-it/index.xml" rel="self" type="application/rss+xml"/><item><title>Release It 读书笔记 - Stability patterns (part2)</title><link>https://ryji.github.io/post/release_it/stability_pattern_part2/</link><pubDate>Sat, 27 Mar 2021 10:16:33 +0800</pubDate><guid>https://ryji.github.io/post/release_it/stability_pattern_part2/</guid><description>
本文为 Release It! 第五章笔记的第二部分，主要介绍服务/应用设计中可以提高系统可用性的模式 (patterns)。这些模式可以降低、减缓或者消除因局部系统出错导致全部服务出错的可能。
Steady State (稳态) 运维/开发人员对生产/测试/开发环境中服务器配置的修改会导致系统处于不稳定的状态。通过流程自动化，在减少/消除人为干预的前提下，完成产品的发布，避免人员错误导致的系统风险。
随着系统的运行，数据库中的记录条数、缓存对内存的占用、日志数量都会不断增多。Steady State 指的是，必须有对应的手段减少这些随着系统运行不断累计增多的资源，将系统保持在一个比较稳定的状态。
数据清洗 随着系统的运行，数据库中的数据会逐渐增长，数据库服务器 IO 占用不断增高导致系统变慢。除了分库分表外，还可以将数据分为热数据和冷数据，两者采用不同的存储方案。
开发人员需要保持热数据所在的数据库中的记录数量稳定，且数据清洗过程不会导致应用出错。
日志 如果日志需要保存在服务器(第三方组件、遗留代码)上，那么最好使用类似 Kafka 的循环日志记法(限制日志的保存时间或磁盘占用空间，使用 logrotate 工具可以很方便地实现这个功能)。
新的应用，特别是使用容器化部署方式的应用，最好采用集中化的日志存储方案。所有服务通过 Logstash 等组件将日志集中在同一个地方，建立索引后供开发/运维人员检索。
内存中的cache 建立缓存时，需要考虑两个问题：1.key 的数量是否有上限；2.缓存的数据是否会被更改。如果缓存的 item 数量无上限，那么必须限制缓存的数量或者缓存占用的内存。如果缓存的数据需要进行修改，那么必须限制缓存的生效时间，或者采用定时刷新缓存的方案。
总结
避免/减少人为干预 结合业务逻辑进行数据清洗 清理日志 限制缓存对内存的占用 Handshaking ，Shed Load，Create Back Pressure 服务器应能够保护自己，限制(throttling)自身承载的工作负载。
Handshaking (握手) 在底层通信协议(RS232, TCP)中，handshaking 应用得比较广泛，可以让接收端通知发送端停止发送数据，直到接收端准备完毕。但是在 HTTP 等应用层协议中，handshaking 未被充分利用，导致 Cascading Failures。
通过在服务中加入 health check，负载均衡组件能够获取服务器的负载状态，避免继续对过载的服务继续转发请求。更进一步，当服务发现自身无法保障 SLA 时，可以停止 health check 的响应，这样负载均衡组件就会认为服务不可用，避免服务接收到更多的请求。
Shed Load (丢弃负载) 与 handshaking 相似，shed load 描述的是将系统无法承载的请求丢掉来降低系统负载的方案。通常可以结合SLA，限制系统并发请求的数量来丢弃过多的请求。</description></item><item><title>Release It 读书笔记 - Stability patterns (part1)</title><link>https://ryji.github.io/post/release_it/stability_pattern_part1/</link><pubDate>Sun, 21 Mar 2021 20:45:59 +0800</pubDate><guid>https://ryji.github.io/post/release_it/stability_pattern_part1/</guid><description>
本文为 Release It! 第五章笔记的第一部分，主要介绍服务/应用设计中可以提高系统可用性的模式 (patterns)。这些模式可以降低、减缓或者消除因局部系统出错导致全部服务出错的可能。
Timeout (超时时间) 在进行网络请求时，设置超时时间是很常见的。然而，在系统集成时，第三方的 API 往往不会提供超时时间参数供使用者调用。这时需要采用 timeout 模式调用这些 API，避免因第三方系统的问题导致服务崩溃。
另外，即使在一个系统内部，也会有需要设置超时时间的场景。例如，访问资源池时，访问线程可能会被 block，这时，如果采用 timeout 模式，这些被 block 的线程会在达到超时时间后返回，防止大多数线程被同一个资源阻塞，导致系统无线程可用。另外，使用同步或者信号量原语时，最好也增加 timeout 参数，避免无限制的等待。
另外，在过去的经验中，超时往往会和重试在一起使用。在使用重试时，除了瞬态错误外(丢包)，大部分错误(配置出错，服务出错)都无法通过重试恢复。在 GUI 编程中，因进行重试而阻塞 UI 界面会降低用户体验。在部分场景中，将任务排入队列，在稍晚的时间进行重试也可能会提高系统的鲁棒性。总之，在使用重试时，需要仔细考虑业务要求和错误类型。
timeout 模式和 Fail Fast 模式一体两面，前者用于处理 outbound requests，后者用来处理 incoming requests。
总结
在系统集成点、阻塞线程和资源池访问时使用 timeout 使用 timeout 从异常中恢复 考虑延迟后进行重试 Circuit Breaker (断路保护器) 断路保护器来源于电气学科，共包含三种状态：Closed、Open、Half-Open。断路保护器会代理被保护的请求，并通过统计请求成功/失败的频次来调整自身的状态。如图所示。
状态为 Closed 时，所有的请求都会被转发到实际的服务中，如果请求成功，返回请求结果；如果请求失败，失败频次累加，当失败频次达到上限，则断路保护器会转移到 Open 状态。 当保护器状态为 Open 时，所有的请求都立即返回失败。状态为 Open 的断路保护器经过一定的超时时间后，状态转移到 Half-Open。 状态为 Half-Open 的断路保护器会尝试转发一部分请求(一般为一个)到实际的服务中，如果成功，断路保护器转移到 Closed，失败则转移到 Open。 断路保护器也用于处理 outbound requests，它提供了一种自动降级的机制：当系统需要的资源不可用时，不再对其进行频繁访问。在断路保护器状态为 Open 时，往往需要使用 fallback 进行处理。</description></item><item><title>Release It 读书笔记- stability antipatterns (part2)</title><link>https://ryji.github.io/post/release_it/stability_antipattern_part2/</link><pubDate>Sun, 14 Mar 2021 21:47:37 +0800</pubDate><guid>https://ryji.github.io/post/release_it/stability_antipattern_part2/</guid><description>
本文为 Release It! 第四章的笔记的第二部分，主要介绍服务/应用设计中可能引入的反模式 (antipatterns)，这些错误的设计会导致、加速系统的崩溃。在系统设计时，应尽可能地避免这些反模式。然而，错误是不可避免的，因此，还需要进一步了解这些错误发生后，会如何影响整个系统的运行。
Blocked Threads (阻塞的线程) 在访问处理临界区的资源(cache, resource pool, 外部系统)时，线程会被其他同时访问此资源的线程阻塞。线程阻塞往往是随机出现的，出现的概率随着系统负载的增大而增大。在开发环境，由于系统的用户远低于生产环境的用户，很难发现此类问题。
在领域模型中使用线程同步方法是一种反模式，这种设计使得应用无法横向扩展。一种避免使用线程同步方法的设计是使领域模型对象不可变(immutable)，使用此对象进行查询和展示；当需要改变状态时，需要构造 Command 对象，也就是 CQRS(Command Query Responsibility Separation) 模式。
总结
阻塞的线程是大多数错误产生的最直接原因 仔细检查资源池 使用经过验证的多线程原语 使用 Timeouts 进行防御 留意引用的第三方库 Self-Denial Attacks (自我拒绝攻击) Self-Denial Attacks是一种人和系统共同参与下发生的巧合，其结果类似于外部对系统进行攻击。
例如，超级话题，电商平台中 bug 优惠券、bug 价，都会使得系统在短期内产生对同一对象的大量请求。这些请求有可能会拖垮整个系统，导致失败。
处理这种问题的理想手段是使用 share-nothing 架构。然而，系统间总是需要共享部分数据。因此，在必须要共享资源时，尽可能地使用中间件进行解耦；在全局锁失效时，使用 fallback 方案进行处理(悲观锁-&amp;gt;乐观锁)
总结
保持沟通(商务事件) 保护共享资源 对热点数据快速重分配(热点数据自动多点备份，防止单机访问瓶颈) Scaling Effects (扩展的影响) 随着系统的横向扩展，一些在开发/测试环境中不存在的问题会逐渐在生产环境中暴露出来。
在非生产环境或者传统架构中，P2P 通信是一种常见的策略。但随着系统进行横向扩展，这种通信方式会导致O( (N^2) )的数据流量，因此，推荐采用以下几种方式进行通信：
UDP 广播(网络效率不高) TCP/UDP 组播 publish/subscribe 模式 消息队列 共享资源/服务，随着系统 scaling，会慢慢变成系统的瓶颈。需要尽可能减少资源的共享，做到share-nothing。
总结</description></item><item><title>Release It 读书笔记- stability antipatterns (part1)</title><link>https://ryji.github.io/post/release_it/stability_antipattern_part1/</link><pubDate>Sun, 14 Mar 2021 19:06:02 +0800</pubDate><guid>https://ryji.github.io/post/release_it/stability_antipattern_part1/</guid><description>
本文为 Release It! 第四章的笔记，主要介绍服务/应用设计中可能引入的反模式 (antipatterns)，这些错误的设计会导致、加速系统的崩溃。在系统设计时，应尽可能地避免这些反模式。然而，错误是不可避免的，因此，还需要进一步了解这些错误发生后，会如何影响整个系统的运行。
Integration Points (系统集成点) 系统之间两两集成 (复杂度 ( N^2 ) ) vs 通过中间件集成 (复杂度 ( 2N ))
TCP TCP协议具有以下特点：
客户端发送SYN包时，如果没有服务在监听此端口，则客户端会理解获得一个异常，此处耗时 &amp;lt; 10ms 客户端发送SYN包后，如果服务端处于过载状态，此连接可能会进入网络栈listen queue中。listen queue中的连接状态为SYN包已发送成功，但SYN/ACK未返回。如果listen queue已满，客户端发送SYN包会立即返回失败；但是，listen queue中的连接可能会被阻塞分钟级别的超时时间，导致open方法无法返回，直到服务端能够处理此连接 同样的，客户端发送消息并等待服务端的返回时，可能也会因服务端处理能力的问题而被阻塞。read方法的阻塞时间默认为最大值 TCP连接关闭后，默认TIME_WAIT时间段内不可重用此端口，避免因delay的消息发送到此端口，导致旧连接的消息发送的新创建的连接上 因此，网络栈的失败可以分为两类：快速失败和慢速失败。后者可能会导致线程被阻塞数以分钟计的时间，导致资源的消耗，降低系统的承载能力。
理论上，socket连接是抽象的概念，只要通信的两端认为自身的连接处于open状态，即使物理连接短暂断开，在恢复后也不会影响双方的通信。但是，由于防火墙/NAT等网络中间件的存在，非活跃状态的socket连接可能会被清理出路由表，随后通信的一端发出的数据被防火墙/中间件丢弃，导致双方通信失败。此问题在数据库连接池中是一种常见的问题，通常的解决方案是：将连接池实现为FIFO的，定时使用特定SQL检测处于IDLE状态的连接。
HTTP HTTP 协议是建立在 TCP 的基础上，因此，上一节描述的 TCP 的问题在 HTTP 协议中都有可能发生。另外，HTTP还有自身特有的一些问题：
服务端只接收 TCP，不接收 HTTP 请求 服务端只接受连接，不读取请求的数据。如果请求的 body 较大，可能会导致服务端的 TCP RWND 被撑爆，甚至导致请求无法发送成功 服务端可能返回请求端无法识别的状态码 服务端返回的数据类型可能与请求端期望得到的不一致，或者请求端不知道怎么处理此返回值 服务端声明的数据类型与其包含的数据不一致，如声明为 json，实际包含的为 plaintext 第三方(供应商)API库 第三方 API 库的质量往往不如服务端的质量。可能会导致阻塞的问题主要有以下几个：资源池，socket 连接，HTTP 连接等。在第三方库中发现的缺陷，往往只能通过固定时间重启应用，或者绕开异常代码来规避
总结
注意不可避免的集成点 为多种类型的 fail 做准备 了解何时需要抽象，何时需要了解抽象背后的概念 错误会在系统间快速传播 应用 Circuit Breaker, TimeoutsDecoupling Middleware, 和 Handshaking 来处理此节的问题 Chain Reactions (链式反应) 横向扩展+负载均衡是提高系统可用性的常用方法。然而，由于 Chain Reactions 的存在，当一个节点因过载导致崩溃时，此节点的处理压力会转移到其它节点，导致其它节点处理压力加大，提高了其它节点崩溃的风险。在极端情况下，节点会一个个地崩溃，且崩溃之间的时间间隔逐渐降低，最终导致整个集群不可用。</description></item></channel></rss>