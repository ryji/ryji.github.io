<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>读书笔记 on Clarity</title><link>https://ryji.github.io/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/</link><description>Recent content in 读书笔记 on Clarity</description><generator>Hugo -- gohugo.io</generator><copyright>Copyright © 2008–2018, Steve Francia and the Hugo Authors; all rights reserved.</copyright><lastBuildDate>Sat, 27 Mar 2021 10:16:33 +0800</lastBuildDate><atom:link href="https://ryji.github.io/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/index.xml" rel="self" type="application/rss+xml"/><item><title>Release It 读书笔记 - Stability patterns (part2)</title><link>https://ryji.github.io/post/release_it/stability_pattern_part2/</link><pubDate>Sat, 27 Mar 2021 10:16:33 +0800</pubDate><guid>https://ryji.github.io/post/release_it/stability_pattern_part2/</guid><description>
本文为 Release It! 第五章笔记的第二部分，主要介绍服务/应用设计中可以提高系统可用性的模式 (patterns)。这些模式可以降低、减缓或者消除因局部系统出错导致全部服务出错的可能。
Steady State (稳态) 运维/开发人员对生产/测试/开发环境中服务器配置的修改会导致系统处于不稳定的状态。通过流程自动化，在减少/消除人为干预的前提下，完成产品的发布，避免人员错误导致的系统风险。
随着系统的运行，数据库中的记录条数、缓存对内存的占用、日志数量都会不断增多。Steady State 指的是，必须有对应的手段减少这些随着系统运行不断累计增多的资源，将系统保持在一个比较稳定的状态。
数据清洗 随着系统的运行，数据库中的数据会逐渐增长，数据库服务器 IO 占用不断增高导致系统变慢。除了分库分表外，还可以将数据分为热数据和冷数据，两者采用不同的存储方案。
开发人员需要保持热数据所在的数据库中的记录数量稳定，且数据清洗过程不会导致应用出错。
日志 如果日志需要保存在服务器(第三方组件、遗留代码)上，那么最好使用类似 Kafka 的循环日志记法(限制日志的保存时间或磁盘占用空间，使用 logrotate 工具可以很方便地实现这个功能)。
新的应用，特别是使用容器化部署方式的应用，最好采用集中化的日志存储方案。所有服务通过 Logstash 等组件将日志集中在同一个地方，建立索引后供开发/运维人员检索。
内存中的cache 建立缓存时，需要考虑两个问题：1.key 的数量是否有上限；2.缓存的数据是否会被更改。如果缓存的 item 数量无上限，那么必须限制缓存的数量或者缓存占用的内存。如果缓存的数据需要进行修改，那么必须限制缓存的生效时间，或者采用定时刷新缓存的方案。
总结
避免/减少人为干预 结合业务逻辑进行数据清洗 清理日志 限制缓存对内存的占用 Handshaking ，Shed Load，Create Back Pressure 服务器应能够保护自己，限制(throttling)自身承载的工作负载。
Handshaking (握手) 在底层通信协议(RS232, TCP)中，handshaking 应用得比较广泛，可以让接收端通知发送端停止发送数据，直到接收端准备完毕。但是在 HTTP 等应用层协议中，handshaking 未被充分利用，导致 Cascading Failures。
通过在服务中加入 health check，负载均衡组件能够获取服务器的负载状态，避免继续对过载的服务继续转发请求。更进一步，当服务发现自身无法保障 SLA 时，可以停止 health check 的响应，这样负载均衡组件就会认为服务不可用，避免服务接收到更多的请求。
Shed Load (丢弃负载) 与 handshaking 相似，shed load 描述的是将系统无法承载的请求丢掉来降低系统负载的方案。通常可以结合SLA，限制系统并发请求的数量来丢弃过多的请求。</description></item><item><title>Release It 读书笔记 - Stability patterns (part1)</title><link>https://ryji.github.io/post/release_it/stability_pattern_part1/</link><pubDate>Sun, 21 Mar 2021 20:45:59 +0800</pubDate><guid>https://ryji.github.io/post/release_it/stability_pattern_part1/</guid><description>
本文为 Release It! 第五章笔记的第一部分，主要介绍服务/应用设计中可以提高系统可用性的模式 (patterns)。这些模式可以降低、减缓或者消除因局部系统出错导致全部服务出错的可能。
Timeout (超时时间) 在进行网络请求时，设置超时时间是很常见的。然而，在系统集成时，第三方的 API 往往不会提供超时时间参数供使用者调用。这时需要采用 timeout 模式调用这些 API，避免因第三方系统的问题导致服务崩溃。
另外，即使在一个系统内部，也会有需要设置超时时间的场景。例如，访问资源池时，访问线程可能会被 block，这时，如果采用 timeout 模式，这些被 block 的线程会在达到超时时间后返回，防止大多数线程被同一个资源阻塞，导致系统无线程可用。另外，使用同步或者信号量原语时，最好也增加 timeout 参数，避免无限制的等待。
另外，在过去的经验中，超时往往会和重试在一起使用。在使用重试时，除了瞬态错误外(丢包)，大部分错误(配置出错，服务出错)都无法通过重试恢复。在 GUI 编程中，因进行重试而阻塞 UI 界面会降低用户体验。在部分场景中，将任务排入队列，在稍晚的时间进行重试也可能会提高系统的鲁棒性。总之，在使用重试时，需要仔细考虑业务要求和错误类型。
timeout 模式和 Fail Fast 模式一体两面，前者用于处理 outbound requests，后者用来处理 incoming requests。
总结
在系统集成点、阻塞线程和资源池访问时使用 timeout 使用 timeout 从异常中恢复 考虑延迟后进行重试 Circuit Breaker (断路保护器) 断路保护器来源于电气学科，共包含三种状态：Closed、Open、Half-Open。断路保护器会代理被保护的请求，并通过统计请求成功/失败的频次来调整自身的状态。如图所示。
状态为 Closed 时，所有的请求都会被转发到实际的服务中，如果请求成功，返回请求结果；如果请求失败，失败频次累加，当失败频次达到上限，则断路保护器会转移到 Open 状态。 当保护器状态为 Open 时，所有的请求都立即返回失败。状态为 Open 的断路保护器经过一定的超时时间后，状态转移到 Half-Open。 状态为 Half-Open 的断路保护器会尝试转发一部分请求(一般为一个)到实际的服务中，如果成功，断路保护器转移到 Closed，失败则转移到 Open。 断路保护器也用于处理 outbound requests，它提供了一种自动降级的机制：当系统需要的资源不可用时，不再对其进行频繁访问。在断路保护器状态为 Open 时，往往需要使用 fallback 进行处理。</description></item><item><title>Release It 读书笔记- stability antipatterns (part2)</title><link>https://ryji.github.io/post/release_it/stability_antipattern_part2/</link><pubDate>Sun, 14 Mar 2021 21:47:37 +0800</pubDate><guid>https://ryji.github.io/post/release_it/stability_antipattern_part2/</guid><description>
本文为 Release It! 第四章的笔记的第二部分，主要介绍服务/应用设计中可能引入的反模式 (antipatterns)，这些错误的设计会导致、加速系统的崩溃。在系统设计时，应尽可能地避免这些反模式。然而，错误是不可避免的，因此，还需要进一步了解这些错误发生后，会如何影响整个系统的运行。
Blocked Threads (阻塞的线程) 在访问处理临界区的资源(cache, resource pool, 外部系统)时，线程会被其他同时访问此资源的线程阻塞。线程阻塞往往是随机出现的，出现的概率随着系统负载的增大而增大。在开发环境，由于系统的用户远低于生产环境的用户，很难发现此类问题。
在领域模型中使用线程同步方法是一种反模式，这种设计使得应用无法横向扩展。一种避免使用线程同步方法的设计是使领域模型对象不可变(immutable)，使用此对象进行查询和展示；当需要改变状态时，需要构造 Command 对象，也就是 CQRS(Command Query Responsibility Separation) 模式。
总结
阻塞的线程是大多数错误产生的最直接原因 仔细检查资源池 使用经过验证的多线程原语 使用 Timeouts 进行防御 留意引用的第三方库 Self-Denial Attacks (自我拒绝攻击) Self-Denial Attacks是一种人和系统共同参与下发生的巧合，其结果类似于外部对系统进行攻击。
例如，超级话题，电商平台中 bug 优惠券、bug 价，都会使得系统在短期内产生对同一对象的大量请求。这些请求有可能会拖垮整个系统，导致失败。
处理这种问题的理想手段是使用 share-nothing 架构。然而，系统间总是需要共享部分数据。因此，在必须要共享资源时，尽可能地使用中间件进行解耦；在全局锁失效时，使用 fallback 方案进行处理(悲观锁-&amp;gt;乐观锁)
总结
保持沟通(商务事件) 保护共享资源 对热点数据快速重分配(热点数据自动多点备份，防止单机访问瓶颈) Scaling Effects (扩展的影响) 随着系统的横向扩展，一些在开发/测试环境中不存在的问题会逐渐在生产环境中暴露出来。
在非生产环境或者传统架构中，P2P 通信是一种常见的策略。但随着系统进行横向扩展，这种通信方式会导致O(\ N^2\ )的数据流量，因此，推荐采用以下几种方式进行通信：
UDP 广播(网络效率不高) TCP/UDP 组播 publish/subscribe 模式 消息队列 共享资源/服务，随着系统 scaling，会慢慢变成系统的瓶颈。需要尽可能减少资源的共享，做到share-nothing。
总结</description></item><item><title>Release It 读书笔记- stability antipatterns (part1)</title><link>https://ryji.github.io/post/release_it/stability_antipattern_part1/</link><pubDate>Sun, 14 Mar 2021 19:06:02 +0800</pubDate><guid>https://ryji.github.io/post/release_it/stability_antipattern_part1/</guid><description>
本文为 Release It! 第四章的笔记，主要介绍服务/应用设计中可能引入的反模式 (antipatterns)，这些错误的设计会导致、加速系统的崩溃。在系统设计时，应尽可能地避免这些反模式。然而，错误是不可避免的，因此，还需要进一步了解这些错误发生后，会如何影响整个系统的运行。
Integration Points (系统集成点) 系统之间两两集成 (复杂度 \ N^2 \ ) vs 通过中间件集成 (复杂度 \ 2N \ )
TCP TCP协议具有以下特点：
客户端发送SYN包时，如果没有服务在监听此端口，则客户端会理解获得一个异常，此处耗时 &amp;lt; 10ms 客户端发送SYN包后，如果服务端处于过载状态，此连接可能会进入网络栈listen queue中。listen queue中的连接状态为SYN包已发送成功，但SYN/ACK未返回。如果listen queue已满，客户端发送SYN包会立即返回失败；但是，listen queue中的连接可能会被阻塞分钟级别的超时时间，导致open方法无法返回，直到服务端能够处理此连接 同样的，客户端发送消息并等待服务端的返回时，可能也会因服务端处理能力的问题而被阻塞。read方法的阻塞时间默认为最大值 TCP连接关闭后，默认TIME_WAIT时间段内不可重用此端口，避免因delay的消息发送到此端口，导致旧连接的消息发送的新创建的连接上 因此，网络栈的失败可以分为两类：快速失败和慢速失败。后者可能会导致线程被阻塞数以分钟计的时间，导致资源的消耗，降低系统的承载能力。
理论上，socket连接是抽象的概念，只要通信的两端认为自身的连接处于open状态，即使物理连接短暂断开，在恢复后也不会影响双方的通信。但是，由于防火墙/NAT等网络中间件的存在，非活跃状态的socket连接可能会被清理出路由表，随后通信的一端发出的数据被防火墙/中间件丢弃，导致双方通信失败。此问题在数据库连接池中是一种常见的问题，通常的解决方案是：将连接池实现为FIFO的，定时使用特定SQL检测处于IDLE状态的连接。
HTTP HTTP 协议是建立在 TCP 的基础上，因此，上一节描述的 TCP 的问题在 HTTP 协议中都有可能发生。另外，HTTP还有自身特有的一些问题：
服务端只接收 TCP，不接收 HTTP 请求 服务端只接受连接，不读取请求的数据。如果请求的 body 较大，可能会导致服务端的 TCP RWND 被撑爆，甚至导致请求无法发送成功 服务端可能返回请求端无法识别的状态码 服务端返回的数据类型可能与请求端期望得到的不一致，或者请求端不知道怎么处理此返回值 服务端声明的数据类型与其包含的数据不一致，如声明为 json，实际包含的为 plaintext 第三方(供应商)API库 第三方 API 库的质量往往不如服务端的质量。可能会导致阻塞的问题主要有以下几个：资源池，socket 连接，HTTP 连接等。在第三方库中发现的缺陷，往往只能通过固定时间重启应用，或者绕开异常代码来规避
总结</description></item><item><title>High-Performance Browser Networking 读书笔记-TLS</title><link>https://ryji.github.io/post/hnbp/hpbn-tls/</link><pubDate>Sat, 13 Feb 2021 15:19:53 +0800</pubDate><guid>https://ryji.github.io/post/hnbp/hpbn-tls/</guid><description>
引言 TLS (Transport Layer Security)建立在传输层之上，为其它协议提供跨网络的安全传输能力，这种能力包含三个部分：加密、认证、防篡改和伪造。TLS通过非对称加密技术，在非加密信道中，为无先验信息的通信双方提供协商会话秘钥(对称秘钥)的方法；在TLS握手过程中，协议规定了一系列认证方法，使通信双方能够互相认证；最后，TLS提供消息校验码(message authentication code，MAC)来对每一条传输的消息进行校验，防止传输途中的篡改和伪造。
HTTP协议的成功，催生出很多网络中间件：缓存服务器、安全网关、内容过滤器等。基于HTTP协议的新协议可能无法被这种中间件识别，或者会被这些中间件盲目地篡改。因此，在WebSocket协议中，一般会推荐使用HTTPS作为其通信的信道，这样防止消息被中间件篡改。
TLS握手 TLS协议握手过程如下图所示：
时刻 事件 0 ms 建立TCP信道 56 ms 客户端发送其支持的TLS信息，包括版本，支持的加密组件列表，随机数rand_c 84 ms 服务端根据客户端发送的信息，选择一种加密组件，附带服务端的证书和随机数rand_s，发送到客户端 112 ms 如果双方对版本和加密方式达成一致，且服务端的证书在客户端认证通过。客户端生成一个对称秘钥key，使用服务端的公钥加密后的发送到服务端，并通知服务端切换到加密传输模式 140 ms 服务端使用私钥解密客户端发送的对称秘钥key，并通过消息的MAC校验消息的完整性。基于对称秘钥key, rand_c, rand_s计算出随后与客户端通信使用的秘钥，并基于此秘钥发送加密的finish消息 168 ms 客户端基于对称秘钥key, rand_c, rand_s计算出对称秘钥，使用此秘钥解密服务端的消息。至此，加密通信信道完全建立 协议扩展 ALPN（Application Layer Protocol Negotiation） 使用自定义协议时，通信的双方需要进行协商，例如http协议升级到2.0。使用ALPN技术，可以利用现有的TLS 443端口协商服务协议，其过程为：客户端在ClientHello消息中增加ProtocolNameList字段，其值为客户端支持的协议列表，服务端读取ProtocolNameList后，根据自身支持的协议，在ServerHello消息中，增加ProtocolName字段，其值为服务端选定的自定义协议。
SNI(server Name Indication) 同一个IP地址host多个不同的服务，每个服务都有各自的TLS证书</description></item><item><title>High-Performance Browser Networking 读书笔记-UDP</title><link>https://ryji.github.io/post/hnbp/hpbn-udp/</link><pubDate>Fri, 12 Feb 2021 12:15:10 +0800</pubDate><guid>https://ryji.github.io/post/hnbp/hpbn-udp/</guid><description>
引言 UDP(User Datagram Protocol)协议，不同于TCP，是一种无连接的不可靠协议。在IP层的基础上，UDP协议增加了四个字段，且其中的port为可选的，checkSum也可以被业务层忽略。因此，UDP协议具有以下特点：
不保证消息送达（没有ACK，重传，timeout） 不保证消息顺序（没有packet编码，没有HOL问题） 无连接（没有连接建立/断开的状态） 无拥塞控制 另外，TCP为面向流的协议，因此，一条消息可能会被分片传输；而UDP协议不会有此情况，一条消息对应一个IP包，不会有分片的问题。
UDP与NAT 为了解决IPV4地址不足的问题，在1994年，人们提出使用NAT(Network Address Translator)设备将内网地址映射到外网地址，这样不同的子网就可以共享内网地址，来解决IPV4地址耗尽的问题。虽然这只是临时的解决方案，但如今NAT已经成为互联网网络基础设施的一部分。
NAT设备维护内部IP、端口与外部IP、端口的映射。TCP协议有明确的连接建立/断开流程，NAT设备可以利用在连接断开时，删除建立的映射关系；然而，UDP协议是无连接的，NAT设备必须维护映射表，处于内网的设备才能接受外部发过来的UDP消息。另外，NAT设备的映射表在没有流量经过一段时间后，会将映射关系置为timeout状态来删除这条映射关系记录。对于UDP应用来说，可以使用双向的keepAlive包来维持NAT设备的映射关系。 另外，虽然理论上NAT设备可以使用TCP连接的状态转移来维护映射关系，但实际上，大多数NAT设备都采用会话超时策略处理UDP和TCP连接。因此，当TCP连接失效时，可能是NAT设备的原因。
STUN, TURN and ICE UDP连接建立时，如果客户端设备隐藏在NAT设备之后，那么必须知道该设备的公网地址才能建立建立，而且，在NAT设备中，必须维护有此公网地址和设备内网地址的映射关系，进入此子网的流量才能经过NAT设备进入目标设备。STUN，TURN和ICE提供了建立端到端UDP连接的方法。
STUN STUN(Session Traversal Utilities for NAT)可以确认应用部署的环境是否存在NAT设备，如果存在NAT设备，则可以获取此连接的外网地址。STUN协议需要使用部署在外网环境的STUN服务器才能完成上述功能。
应用发出一条binding请求到STUN服务器，服务器返回应用的公网IP和端口 应用利用映射的公网IP和端口进行UDP通信 binding请求在请求的路由路径中建立了内外网地址映射关系，使用公网地址的入站流量可以正确地路由到内网地址 STUN协议也定义了一种keepalive的机制，用来维持NAT映射关系防止因超时导致的自动清理 TURN 在部分网络环境下，可能无法通过STUN建立UDP端到端连接。例如，部分企业级网络的防火墙可能禁用UDP协议。在此情况下，可以转用TURN(Traversal Using Relays around NAT)协议。顾名思义，TURN协议依赖公网上的转发来交换peer之间的数据
通信双方都发送allocate请求到同一个TURN服务器，进行通信协商 当协商完成后，通信双方发送数据到TURN服务器，服务器进行数据转发 google libjingle提供了STUN，TURN，ICE协商的能力，而且被使用在google talk等产品中。根据其文档，92%的P2P连接可以直接使用STUN建立，剩余的使用TURN建立
ICE ICE( Interactive Connectivity Establishment)提供了建立高效的P2P通信的方法。优先直接连接，其次考虑使用STUN，在其他方式建立失败后，使用TURN
Checklist 必须适应多种网络环境 应当控制数据传输速率 应当进行拥塞控制 应当与采用与TCP类似的方式使用带宽 应当能够在丢失数据后进行重传 不应当发送大于MTU的数据包 应当处理数据包丢失、重复、乱序 应当能够在2min的延时下保持鲁棒性 应当支持IPV4 UDPcheckSum特性，必须支持IPV6 checkSum 在需要时，可以发送keepalive包(最小间隔不高于15s)</description></item><item><title>High-Performance Browser Networking 读书笔记-TCP</title><link>https://ryji.github.io/post/hnbp/hpbn-tcp/</link><pubDate>Sat, 06 Feb 2021 22:43:58 +0800</pubDate><guid>https://ryji.github.io/post/hnbp/hpbn-tcp/</guid><description>
引言 TCP/IP网络是互联网的核心，IP(Internet Protocal)提供了host-host的路由和寻址协议，TCP(Transmission Control Protocal)协议在不可靠的通信管道上建立了可靠的网络传输，保障接收端接收到的数据和发送端发送的数据内容和顺序一致。虽然协议没有要求，但如今大部分HTTP的实现都建立在TCP协议的基础上。
TCP协议概述 三次握手 TCP协议建立连接时需要进行三次握手，如下表所示
发送端 接收端 SYN (x=rand()) ------&amp;gt; - - &amp;lt;------ SYN ACK (x+1 y=rand()) ACK (y+1 x+1) ------&amp;gt; - 发送端在发送ACK之后就可以向接收端发送业务数据，接收端需要在接收到发送端的ACK之后才能向发送端发送业务数据。如果端到端通信的延时较大(例如：物理距离较远)，那么建立起TCP连接的耗时较长。因此，基于TCP协议的一个常用的优化方式是重用已经建立的连接。
TFO(TCP FAST OPEN, support on Linux 3.7+ kernel)技术可以在SYN packet中发送业务数据，降低部分因三次握手导致的延时。但这种技术只可以应用在部分类型的HTTP请求中，且SYN包中携带的数据包大小也有一定的限制。
拥塞避免和控制 flow control flow control是一种用来避免发送过多的数据导致接收端过载的机制，为了达到这一目的，通信的双方需要在每个ACK包中添加自身的recieve window(rwnd)，使得发送可以根据接收方的rwnd来调整发送速度。当rwnd降为0时，发送端停止向接收端发送数据，直到接收端将自身buffer中的数据处理完毕
最初版本的TCP协议为rwnd分配了16bit的空间，这样限定TCP通信过程中，双方的revieve buffer不能超过 \2^{16} = 65536\ bytes。随着应用对数据传输能力要求越来越高，RFC 1323提出 Window Scaling 技术，在ACK packet中将rwnd左移，recieve buffer提高到1G。
slow-start flow-control解决了通信双方不会导致对方过载的问题，但实际上网络中的各个节点处理能力和带宽各有差异。在通信建立时，发送/接收双方无法了解参与通信各个节点的处理能力；随着通信的进行，网络环境发生变化，这时候也需要持续调整数据传输速率来使用网络状况。1988年，Van Jacobson 和 Michael J.</description></item></channel></rss>