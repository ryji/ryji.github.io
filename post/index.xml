<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Posts on Clarity</title><link>https://ryji.github.io/post/</link><description>Recent content in Posts on Clarity</description><generator>Hugo -- gohugo.io</generator><copyright>Copyright © 2008–2018, Steve Francia and the Hugo Authors; all rights reserved.</copyright><lastBuildDate>Wed, 04 May 2022 18:00:33 +0800</lastBuildDate><atom:link href="https://ryji.github.io/post/index.xml" rel="self" type="application/rss+xml"/><item><title>Causal Clock</title><link>https://ryji.github.io/post/csharp/orleans/transaction/orleans_transaction_causalclock/</link><pubDate>Wed, 04 May 2022 18:00:33 +0800</pubDate><guid>https://ryji.github.io/post/csharp/orleans/transaction/orleans_transaction_causalclock/</guid><description>
引言 orleans 项目中，考虑因果性时钟的一种实现。
实现 实现要点 能够保持输出时间的递增性 保证不会因为服务器与NTP服务器同步时间，导致时间戳倒退 代码 1public class CausalClock 2{ 3private readonly object lockable = new object(); 4private readonly IClock clock; 5private long previous; 67public CausalClock(IClock clock) 8{ 9this.clock = clock ?? throw new ArgumentNullException(nameof(clock)); 10} 1112public DateTime UtcNow() 13{ 14lock (this.lockable) 15{ 16// 取最近一次tick + 1 与当前时间的tick的最大值 17var ticks = previous = Math.Max(previous + 1, this.clock.UtcNow().Ticks); 18return new DateTime(ticks, DateTimeKind.Utc); 19} 20} 2122public DateTime Merge(DateTime timestamp) 23{ 24lock (this.</description></item><item><title>Release It 读书笔记 - Stability patterns (part2)</title><link>https://ryji.github.io/post/release_it/stability_pattern_part2/</link><pubDate>Sat, 27 Mar 2021 10:16:33 +0800</pubDate><guid>https://ryji.github.io/post/release_it/stability_pattern_part2/</guid><description>
本文为 Release It! 第五章笔记的第二部分，主要介绍服务/应用设计中可以提高系统可用性的模式 (patterns)。这些模式可以降低、减缓或者消除因局部系统出错导致全部服务出错的可能。
Steady State (稳态) 运维/开发人员对生产/测试/开发环境中服务器配置的修改会导致系统处于不稳定的状态。通过流程自动化，在减少/消除人为干预的前提下，完成产品的发布，避免人员错误导致的系统风险。
随着系统的运行，数据库中的记录条数、缓存对内存的占用、日志数量都会不断增多。Steady State 指的是，必须有对应的手段减少这些随着系统运行不断累计增多的资源，将系统保持在一个比较稳定的状态。
数据清洗 随着系统的运行，数据库中的数据会逐渐增长，数据库服务器 IO 占用不断增高导致系统变慢。除了分库分表外，还可以将数据分为热数据和冷数据，两者采用不同的存储方案。
开发人员需要保持热数据所在的数据库中的记录数量稳定，且数据清洗过程不会导致应用出错。
日志 如果日志需要保存在服务器(第三方组件、遗留代码)上，那么最好使用类似 Kafka 的循环日志记法(限制日志的保存时间或磁盘占用空间，使用 logrotate 工具可以很方便地实现这个功能)。
新的应用，特别是使用容器化部署方式的应用，最好采用集中化的日志存储方案。所有服务通过 Logstash 等组件将日志集中在同一个地方，建立索引后供开发/运维人员检索。
内存中的cache 建立缓存时，需要考虑两个问题：1.key 的数量是否有上限；2.缓存的数据是否会被更改。如果缓存的 item 数量无上限，那么必须限制缓存的数量或者缓存占用的内存。如果缓存的数据需要进行修改，那么必须限制缓存的生效时间，或者采用定时刷新缓存的方案。
总结
避免/减少人为干预 结合业务逻辑进行数据清洗 清理日志 限制缓存对内存的占用 Handshaking ，Shed Load，Create Back Pressure 服务器应能够保护自己，限制(throttling)自身承载的工作负载。
Handshaking (握手) 在底层通信协议(RS232, TCP)中，handshaking 应用得比较广泛，可以让接收端通知发送端停止发送数据，直到接收端准备完毕。但是在 HTTP 等应用层协议中，handshaking 未被充分利用，导致 Cascading Failures。
通过在服务中加入 health check，负载均衡组件能够获取服务器的负载状态，避免继续对过载的服务继续转发请求。更进一步，当服务发现自身无法保障 SLA 时，可以停止 health check 的响应，这样负载均衡组件就会认为服务不可用，避免服务接收到更多的请求。
Shed Load (丢弃负载) 与 handshaking 相似，shed load 描述的是将系统无法承载的请求丢掉来降低系统负载的方案。通常可以结合SLA，限制系统并发请求的数量来丢弃过多的请求。</description></item><item><title>Release It 读书笔记 - Stability patterns (part1)</title><link>https://ryji.github.io/post/release_it/stability_pattern_part1/</link><pubDate>Sun, 21 Mar 2021 20:45:59 +0800</pubDate><guid>https://ryji.github.io/post/release_it/stability_pattern_part1/</guid><description>
本文为 Release It! 第五章笔记的第一部分，主要介绍服务/应用设计中可以提高系统可用性的模式 (patterns)。这些模式可以降低、减缓或者消除因局部系统出错导致全部服务出错的可能。
Timeout (超时时间) 在进行网络请求时，设置超时时间是很常见的。然而，在系统集成时，第三方的 API 往往不会提供超时时间参数供使用者调用。这时需要采用 timeout 模式调用这些 API，避免因第三方系统的问题导致服务崩溃。
另外，即使在一个系统内部，也会有需要设置超时时间的场景。例如，访问资源池时，访问线程可能会被 block，这时，如果采用 timeout 模式，这些被 block 的线程会在达到超时时间后返回，防止大多数线程被同一个资源阻塞，导致系统无线程可用。另外，使用同步或者信号量原语时，最好也增加 timeout 参数，避免无限制的等待。
另外，在过去的经验中，超时往往会和重试在一起使用。在使用重试时，除了瞬态错误外(丢包)，大部分错误(配置出错，服务出错)都无法通过重试恢复。在 GUI 编程中，因进行重试而阻塞 UI 界面会降低用户体验。在部分场景中，将任务排入队列，在稍晚的时间进行重试也可能会提高系统的鲁棒性。总之，在使用重试时，需要仔细考虑业务要求和错误类型。
timeout 模式和 Fail Fast 模式一体两面，前者用于处理 outbound requests，后者用来处理 incoming requests。
总结
在系统集成点、阻塞线程和资源池访问时使用 timeout 使用 timeout 从异常中恢复 考虑延迟后进行重试 Circuit Breaker (断路保护器) 断路保护器来源于电气学科，共包含三种状态：Closed、Open、Half-Open。断路保护器会代理被保护的请求，并通过统计请求成功/失败的频次来调整自身的状态。如图所示。
状态为 Closed 时，所有的请求都会被转发到实际的服务中，如果请求成功，返回请求结果；如果请求失败，失败频次累加，当失败频次达到上限，则断路保护器会转移到 Open 状态。 当保护器状态为 Open 时，所有的请求都立即返回失败。状态为 Open 的断路保护器经过一定的超时时间后，状态转移到 Half-Open。 状态为 Half-Open 的断路保护器会尝试转发一部分请求(一般为一个)到实际的服务中，如果成功，断路保护器转移到 Closed，失败则转移到 Open。 断路保护器也用于处理 outbound requests，它提供了一种自动降级的机制：当系统需要的资源不可用时，不再对其进行频繁访问。在断路保护器状态为 Open 时，往往需要使用 fallback 进行处理。</description></item><item><title>Kafka basic intro</title><link>https://ryji.github.io/post/kafka/kafka_basic_intro/</link><pubDate>Mon, 15 Mar 2021 22:37:05 +0800</pubDate><guid>https://ryji.github.io/post/kafka/kafka_basic_intro/</guid><description>
Apache Kafka 是一种 publish/subscibe 类型的消息系统，常用作系统间异步通信的中间件，降低系统的耦合。其突出优点为：支持多生产/消费者、基于磁盘的消息存储、水平扩展性、高性能。
message &amp;amp; batch kafka 中的基本数据单元是消息(message)，其概念类似于数据库中的行。为了提高读写效率，消息是以批(batch)的形式写入 kafka 中，一个 batch 是一组消息的集合。通过这种方法，降低传输消息的网络损耗；另外，batch 一般经过压缩，进一步提高了数据传输效率。batch 的大小和消息传输的时延(latency)正相关。
在 kafka 中，虽然消息只是一组byte，但通常推荐将消息组织成某种可序列化/反序列化的格式。常用的格式有 JSON, XML 和 Avro 。
topic 在 kafka 中，消息使用主题(Topic)分类，其概念类似于数据库中的表。不同类型的消息使用不同的 topic，应用系统只需发布/订阅自身业务相关的 topic 消息。每一个 Topic 又有多个分区(partition)。在一个 kafka 集群中，不同的分区可以分布在不同的节点上，提高消息系统的水平扩展能力；同一个分区可以在多个节点上冗余，提高消息系统的容灾和可用性。
producer &amp;amp; consumer Producer(生产者)是 kafka 中产出消息的单元。在默认情况下，生产者不关心消息发送到哪个分区，系统会自动进行消息的负载均衡。
Consumer(消费者)是订阅并消费消息的单元；一组订阅同一个 topic 的 consumer 构成了一个 consumer group。在一个 consumer group 中， 同一个 partition 的消息最多只能被一个 consumer 消费，即对任一一个topic：consumer 的数量 &amp;lt;= partition 数量。某些极其热门的消息应分配更多的分区，防止 partition 的数量造成整个系统的性能瓶颈。
kafka 中，每条消息都会有其对应在当前 partition 中的 offset，消费者通过消息的在该 partition 的偏移量(offset)来进行消费。实际中，可以在 ZooKeeper 或者 kafka 中记录当前topic - partition 被当前的 consumer group 消费的 offset，可以保障 consumer 重启后也不会丢失其处理消息的位置。</description></item><item><title>Release It 读书笔记- stability antipatterns (part2)</title><link>https://ryji.github.io/post/release_it/stability_antipattern_part2/</link><pubDate>Sun, 14 Mar 2021 21:47:37 +0800</pubDate><guid>https://ryji.github.io/post/release_it/stability_antipattern_part2/</guid><description>
本文为 Release It! 第四章的笔记的第二部分，主要介绍服务/应用设计中可能引入的反模式 (antipatterns)，这些错误的设计会导致、加速系统的崩溃。在系统设计时，应尽可能地避免这些反模式。然而，错误是不可避免的，因此，还需要进一步了解这些错误发生后，会如何影响整个系统的运行。
Blocked Threads (阻塞的线程) 在访问处理临界区的资源(cache, resource pool, 外部系统)时，线程会被其他同时访问此资源的线程阻塞。线程阻塞往往是随机出现的，出现的概率随着系统负载的增大而增大。在开发环境，由于系统的用户远低于生产环境的用户，很难发现此类问题。
在领域模型中使用线程同步方法是一种反模式，这种设计使得应用无法横向扩展。一种避免使用线程同步方法的设计是使领域模型对象不可变(immutable)，使用此对象进行查询和展示；当需要改变状态时，需要构造 Command 对象，也就是 CQRS(Command Query Responsibility Separation) 模式。
总结
阻塞的线程是大多数错误产生的最直接原因 仔细检查资源池 使用经过验证的多线程原语 使用 Timeouts 进行防御 留意引用的第三方库 Self-Denial Attacks (自我拒绝攻击) Self-Denial Attacks是一种人和系统共同参与下发生的巧合，其结果类似于外部对系统进行攻击。
例如，超级话题，电商平台中 bug 优惠券、bug 价，都会使得系统在短期内产生对同一对象的大量请求。这些请求有可能会拖垮整个系统，导致失败。
处理这种问题的理想手段是使用 share-nothing 架构。然而，系统间总是需要共享部分数据。因此，在必须要共享资源时，尽可能地使用中间件进行解耦；在全局锁失效时，使用 fallback 方案进行处理(悲观锁-&amp;gt;乐观锁)
总结
保持沟通(商务事件) 保护共享资源 对热点数据快速重分配(热点数据自动多点备份，防止单机访问瓶颈) Scaling Effects (扩展的影响) 随着系统的横向扩展，一些在开发/测试环境中不存在的问题会逐渐在生产环境中暴露出来。
在非生产环境或者传统架构中，P2P 通信是一种常见的策略。但随着系统进行横向扩展，这种通信方式会导致O($N^2$)的数据流量，因此，推荐采用以下几种方式进行通信：
UDP 广播(网络效率不高) TCP/UDP 组播 publish/subscribe 模式 消息队列 共享资源/服务，随着系统 scaling，会慢慢变成系统的瓶颈。需要尽可能减少资源的共享，做到share-nothing。
总结
检查测试环境和生产环境的 scale 规模，确定是否会有 scaling effect 注意 P2P 通信 注意共享资源 Unbalanced Capacities (容量不平衡) 在生产环境中，访问前端服务的客户端(浏览器/App)可能数以百万计，在这种情况下，前端服务和后端服务、后端服务和后端服务之间都可能会发生负载不平衡的问题。随着系统的运行，热门和非热门的服务时刻变化，这进一步导致了不同系统之间的容量不平衡。热点事件的发生，也会加剧这种问题。</description></item><item><title>Release It 读书笔记- stability antipatterns (part1)</title><link>https://ryji.github.io/post/release_it/stability_antipattern_part1/</link><pubDate>Sun, 14 Mar 2021 19:06:02 +0800</pubDate><guid>https://ryji.github.io/post/release_it/stability_antipattern_part1/</guid><description>
本文为 Release It! 第四章的笔记，主要介绍服务/应用设计中可能引入的反模式 (antipatterns)，这些错误的设计会导致、加速系统的崩溃。在系统设计时，应尽可能地避免这些反模式。然而，错误是不可避免的，因此，还需要进一步了解这些错误发生后，会如何影响整个系统的运行。
Integration Points (系统集成点) 系统之间两两集成 (复杂度 $N^2$) vs 通过中间件集成 (复杂度 $2N$)
TCP TCP协议具有以下特点：
客户端发送SYN包时，如果没有服务在监听此端口，则客户端会理解获得一个异常，此处耗时 &amp;lt; 10ms 客户端发送SYN包后，如果服务端处于过载状态，此连接可能会进入网络栈listen queue中。listen queue中的连接状态为SYN包已发送成功，但SYN/ACK未返回。如果listen queue已满，客户端发送SYN包会立即返回失败；但是，listen queue中的连接可能会被阻塞分钟级别的超时时间，导致open方法无法返回，直到服务端能够处理此连接 同样的，客户端发送消息并等待服务端的返回时，可能也会因服务端处理能力的问题而被阻塞。read方法的阻塞时间默认为最大值 TCP连接关闭后，默认TIME_WAIT时间段内不可重用此端口，避免因delay的消息发送到此端口，导致旧连接的消息发送的新创建的连接上 因此，网络栈的失败可以分为两类：快速失败和慢速失败。后者可能会导致线程被阻塞数以分钟计的时间，导致资源的消耗，降低系统的承载能力。
理论上，socket连接是抽象的概念，只要通信的两端认为自身的连接处于open状态，即使物理连接短暂断开，在恢复后也不会影响双方的通信。但是，由于防火墙/NAT等网络中间件的存在，非活跃状态的socket连接可能会被清理出路由表，随后通信的一端发出的数据被防火墙/中间件丢弃，导致双方通信失败。此问题在数据库连接池中是一种常见的问题，通常的解决方案是：将连接池实现为FIFO的，定时使用特定SQL检测处于IDLE状态的连接。
HTTP HTTP 协议是建立在 TCP 的基础上，因此，上一节描述的 TCP 的问题在 HTTP 协议中都有可能发生。另外，HTTP还有自身特有的一些问题：
服务端只接收 TCP，不接收 HTTP 请求 服务端只接受连接，不读取请求的数据。如果请求的 body 较大，可能会导致服务端的 TCP RWND 被撑爆，甚至导致请求无法发送成功 服务端可能返回请求端无法识别的状态码 服务端返回的数据类型可能与请求端期望得到的不一致，或者请求端不知道怎么处理此返回值 服务端声明的数据类型与其包含的数据不一致，如声明为 json，实际包含的为 plaintext 第三方(供应商)API库 第三方 API 库的质量往往不如服务端的质量。可能会导致阻塞的问题主要有以下几个：资源池，socket 连接，HTTP 连接等。在第三方库中发现的缺陷，往往只能通过固定时间重启应用，或者绕开异常代码来规避
总结
注意不可避免的集成点 为多种类型的 fail 做准备 了解何时需要抽象，何时需要了解抽象背后的概念 错误会在系统间快速传播 应用 Circuit Breaker, TimeoutsDecoupling Middleware, 和 Handshaking 来处理此节的问题 Chain Reactions (链式反应) 横向扩展+负载均衡是提高系统可用性的常用方法。然而，由于 Chain Reactions 的存在，当一个节点因过载导致崩溃时，此节点的处理压力会转移到其它节点，导致其它节点处理压力加大，提高了其它节点崩溃的风险。在极端情况下，节点会一个个地崩溃，且崩溃之间的时间间隔逐渐降低，最终导致整个集群不可用。</description></item><item><title>微服务入门 - spring boot Rest Api &amp; docker</title><link>https://ryji.github.io/post/spring/spring_boot_with_docker/</link><pubDate>Sun, 28 Feb 2021 19:34:31 +0800</pubDate><guid>https://ryji.github.io/post/spring/spring_boot_with_docker/</guid><description>
本文为微服务入门， 主要介绍如何使用 Spring boot 开发一个 Rest Api 服务，以及如何将此服务打包为 docker image 并运行。
spring boot 实现 Rest Api 依赖项 依赖项主要有两个： spring-boot-starter-web 和 spring-boot-starter-actuator。前者为 spring Rest Api 必需组件，后者提供了health, beans, dump, env,metrics等接口，可以方便地获取服务内部的信息。
1&amp;lt;parent&amp;gt; 2&amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt; 3&amp;lt;artifactId&amp;gt;spring-boot-starter-parent&amp;lt;/artifactId&amp;gt; 4&amp;lt;version&amp;gt;2.3.9.RELEASE&amp;lt;/version&amp;gt; 5&amp;lt;relativePath/&amp;gt; &amp;lt;!-- lookup parent from repository --&amp;gt; 6&amp;lt;/parent&amp;gt; 7&amp;lt;dependencies&amp;gt; 8&amp;lt;dependency&amp;gt; 9&amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt; 10&amp;lt;artifactId&amp;gt;spring-boot-starter-actuator&amp;lt;/artifactId&amp;gt; 11&amp;lt;/dependency&amp;gt; 12&amp;lt;dependency&amp;gt; 13&amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt; 14&amp;lt;artifactId&amp;gt;spring-boot-starter-web&amp;lt;/artifactId&amp;gt; 15&amp;lt;/dependency&amp;gt; 16&amp;lt;/dependencies&amp;gt; 入口 SpringBootApplication 注解标志此类为应用的入口点。
1@SpringBootApplication 2public class DemoApplication { 34public static void main(String[] args) { 5SpringApplication.run(DemoApplication.class, args); 6} 7} controller RestController 注解标志此类为Rest Api，类上的 RequestMapping 注解为类中所有接口的 Rest Uri 前缀，v1 为服务的版本信息。服务的横向扩展特性导致运行环境存在多个实例；服务的快速迭代导致多版本的服务共存。因此，需要使用版本信息来区分和标志同一服务的不同版本。方法 getLicenses 上的注解标志此方法的对应的 Rest Api uri，同时标志此 Api 为 Http Get 请求。</description></item><item><title>High-Performance Browser Networking 读书笔记-TLS</title><link>https://ryji.github.io/post/hnbp/hpbn-tls/</link><pubDate>Sat, 13 Feb 2021 15:19:53 +0800</pubDate><guid>https://ryji.github.io/post/hnbp/hpbn-tls/</guid><description>
引言 TLS (Transport Layer Security)建立在传输层之上，为其它协议提供跨网络的安全传输能力，这种能力包含三个部分：加密、认证、防篡改和伪造。TLS通过非对称加密技术，在非加密信道中，为无先验信息的通信双方提供协商会话秘钥(对称秘钥)的方法；在TLS握手过程中，协议规定了一系列认证方法，使通信双方能够互相认证；最后，TLS提供消息校验码(message authentication code，MAC)来对每一条传输的消息进行校验，防止传输途中的篡改和伪造。
HTTP协议的成功，催生出很多网络中间件：缓存服务器、安全网关、内容过滤器等。基于HTTP协议的新协议可能无法被这种中间件识别，或者会被这些中间件盲目地篡改。因此，在WebSocket协议中，一般会推荐使用HTTPS作为其通信的信道，这样防止消息被中间件篡改。
TLS握手 TLS协议握手过程如下图所示：
时刻 事件 0 ms 建立TCP信道 56 ms 客户端发送其支持的TLS信息，包括版本，支持的加密组件列表，随机数rand_c 84 ms 服务端根据客户端发送的信息，选择一种加密组件，附带服务端的证书和随机数rand_s，发送到客户端 112 ms 如果双方对版本和加密方式达成一致，且服务端的证书在客户端认证通过。客户端生成一个对称秘钥key，使用服务端的公钥加密后的发送到服务端，并通知服务端切换到加密传输模式 140 ms 服务端使用私钥解密客户端发送的对称秘钥key，并通过消息的MAC校验消息的完整性。基于对称秘钥key, rand_c, rand_s计算出随后与客户端通信使用的秘钥，并基于此秘钥发送加密的finish消息 168 ms 客户端基于对称秘钥key, rand_c, rand_s计算出对称秘钥，使用此秘钥解密服务端的消息。至此，加密通信信道完全建立 协议扩展 ALPN（Application Layer Protocol Negotiation） 使用自定义协议时，通信的双方需要进行协商，例如http协议升级到2.0。使用ALPN技术，可以利用现有的TLS 443端口协商服务协议，其过程为：客户端在ClientHello消息中增加ProtocolNameList字段，其值为客户端支持的协议列表，服务端读取ProtocolNameList后，根据自身支持的协议，在ServerHello消息中，增加ProtocolName字段，其值为服务端选定的自定义协议。
SNI(server Name Indication) 同一个IP地址host多个不同的服务，每个服务都有各自的TLS证书</description></item><item><title>High-Performance Browser Networking 读书笔记-UDP</title><link>https://ryji.github.io/post/hnbp/hpbn-udp/</link><pubDate>Fri, 12 Feb 2021 12:15:10 +0800</pubDate><guid>https://ryji.github.io/post/hnbp/hpbn-udp/</guid><description>
引言 UDP(User Datagram Protocol)协议，不同于TCP，是一种无连接的不可靠协议。在IP层的基础上，UDP协议增加了四个字段，且其中的port为可选的，checkSum也可以被业务层忽略。因此，UDP协议具有以下特点：
不保证消息送达（没有ACK，重传，timeout） 不保证消息顺序（没有packet编码，没有HOL问题） 无连接（没有连接建立/断开的状态） 无拥塞控制 另外，TCP为面向流的协议，因此，一条消息可能会被分片传输；而UDP协议不会有此情况，一条消息对应一个IP包，不会有分片的问题。
UDP与NAT 为了解决IPV4地址不足的问题，在1994年，人们提出使用NAT(Network Address Translator)设备将内网地址映射到外网地址，这样不同的子网就可以共享内网地址，来解决IPV4地址耗尽的问题。虽然这只是临时的解决方案，但如今NAT已经成为互联网网络基础设施的一部分。
NAT设备维护内部IP、端口与外部IP、端口的映射。TCP协议有明确的连接建立/断开流程，NAT设备可以利用在连接断开时，删除建立的映射关系；然而，UDP协议是无连接的，NAT设备必须维护映射表，处于内网的设备才能接受外部发过来的UDP消息。另外，NAT设备的映射表在没有流量经过一段时间后，会将映射关系置为timeout状态来删除这条映射关系记录。对于UDP应用来说，可以使用双向的keepAlive包来维持NAT设备的映射关系。 另外，虽然理论上NAT设备可以使用TCP连接的状态转移来维护映射关系，但实际上，大多数NAT设备都采用会话超时策略处理UDP和TCP连接。因此，当TCP连接失效时，可能是NAT设备的原因。
STUN, TURN and ICE UDP连接建立时，如果客户端设备隐藏在NAT设备之后，那么必须知道该设备的公网地址才能建立建立，而且，在NAT设备中，必须维护有此公网地址和设备内网地址的映射关系，进入此子网的流量才能经过NAT设备进入目标设备。STUN，TURN和ICE提供了建立端到端UDP连接的方法。
STUN STUN(Session Traversal Utilities for NAT)可以确认应用部署的环境是否存在NAT设备，如果存在NAT设备，则可以获取此连接的外网地址。STUN协议需要使用部署在外网环境的STUN服务器才能完成上述功能。
应用发出一条binding请求到STUN服务器，服务器返回应用的公网IP和端口 应用利用映射的公网IP和端口进行UDP通信 binding请求在请求的路由路径中建立了内外网地址映射关系，使用公网地址的入站流量可以正确地路由到内网地址 STUN协议也定义了一种keepalive的机制，用来维持NAT映射关系防止因超时导致的自动清理 TURN 在部分网络环境下，可能无法通过STUN建立UDP端到端连接。例如，部分企业级网络的防火墙可能禁用UDP协议。在此情况下，可以转用TURN(Traversal Using Relays around NAT)协议。顾名思义，TURN协议依赖公网上的转发来交换peer之间的数据
通信双方都发送allocate请求到同一个TURN服务器，进行通信协商 当协商完成后，通信双方发送数据到TURN服务器，服务器进行数据转发 google libjingle提供了STUN，TURN，ICE协商的能力，而且被使用在google talk等产品中。根据其文档，92%的P2P连接可以直接使用STUN建立，剩余的使用TURN建立
ICE ICE( Interactive Connectivity Establishment)提供了建立高效的P2P通信的方法。优先直接连接，其次考虑使用STUN，在其他方式建立失败后，使用TURN
Checklist 必须适应多种网络环境 应当控制数据传输速率 应当进行拥塞控制 应当与采用与TCP类似的方式使用带宽 应当能够在丢失数据后进行重传 不应当发送大于MTU的数据包 应当处理数据包丢失、重复、乱序 应当能够在2min的延时下保持鲁棒性 应当支持IPV4 UDPcheckSum特性，必须支持IPV6 checkSum 在需要时，可以发送keepalive包(最小间隔不高于15s)</description></item><item><title>High-Performance Browser Networking 读书笔记-TCP</title><link>https://ryji.github.io/post/hnbp/hpbn-tcp/</link><pubDate>Sat, 06 Feb 2021 22:43:58 +0800</pubDate><guid>https://ryji.github.io/post/hnbp/hpbn-tcp/</guid><description>
引言 TCP/IP网络是互联网的核心，IP(Internet Protocal)提供了host-host的路由和寻址协议，TCP(Transmission Control Protocal)协议在不可靠的通信管道上建立了可靠的网络传输，保障接收端接收到的数据和发送端发送的数据内容和顺序一致。虽然协议没有要求，但如今大部分HTTP的实现都建立在TCP协议的基础上。
TCP协议概述 三次握手 TCP协议建立连接时需要进行三次握手，如下表所示
发送端 接收端 SYN (x=rand()) ------&amp;gt; - - &amp;lt;------ SYN ACK (x+1 y=rand()) ACK (y+1 x+1) ------&amp;gt; - 发送端在发送ACK之后就可以向接收端发送业务数据，接收端需要在接收到发送端的ACK之后才能向发送端发送业务数据。如果端到端通信的延时较大(例如：物理距离较远)，那么建立起TCP连接的耗时较长。因此，基于TCP协议的一个常用的优化方式是重用已经建立的连接。
TFO(TCP FAST OPEN, support on Linux 3.7+ kernel)技术可以在SYN packet中发送业务数据，降低部分因三次握手导致的延时。但这种技术只可以应用在部分类型的HTTP请求中，且SYN包中携带的数据包大小也有一定的限制。
拥塞避免和控制 flow control flow control是一种用来避免发送过多的数据导致接收端过载的机制，为了达到这一目的，通信的双方需要在每个ACK包中添加自身的recieve window(rwnd)，使得发送可以根据接收方的rwnd来调整发送速度。当rwnd降为0时，发送端停止向接收端发送数据，直到接收端将自身buffer中的数据处理完毕
最初版本的TCP协议为rwnd分配了16bit的空间，这样限定TCP通信过程中，双方的revieve buffer不能超过$ 2^{16} = 65536 $ bytes。随着应用对数据传输能力要求越来越高，RFC 1323提出 Window Scaling 技术，在ACK packet中将rwnd左移，recieve buffer提高到1G。
slow-start flow-control解决了通信双方不会导致对方过载的问题，但实际上网络中的各个节点处理能力和带宽各有差异。在通信建立时，发送/接收双方无法了解参与通信各个节点的处理能力；随着通信的进行，网络环境发生变化，这时候也需要持续调整数据传输速率来使用网络状况。1988年，Van Jacobson 和 Michael J.</description></item><item><title>C# version golang singleflight</title><link>https://ryji.github.io/post/csharp/csharp_singleflight/</link><pubDate>Thu, 25 Jun 2020 15:20:33 +0800</pubDate><guid>https://ryji.github.io/post/csharp/csharp_singleflight/</guid><description>
引言 GroupCache 是 go 语言的一个开源项目，其目标提供去中心节点的 P2P 分布式缓存代替 memcached。其中使用到的技术有：LRU cache，一致性哈希，并发请求压缩等。该项目已在 Google 的多个服务中使用。
本文使用 C# 实现 GroupCache 中用到并发请求压缩技术，并使用单元测试验证其功能。
实现 实现要点 需要记录所有执行中的请求，才能在新的请求进来时进行请求压缩，使用字典_onFlight记录；字典_onFlight存在多线程读写问题，需要使用锁来保护； 需要记录请求产生的结果和异常，才能在被阻塞的线程恢复后，将其他线程产生的结果返回到调用方。因此，在OnFlightCallRes添加Res和Exception字段 为了实现请求压缩，需要阻塞/恢复请求，且阻塞/恢复的单位是每一个同key的请求。使用ManualResetEventSlim进行线程的阻塞/恢复。因为阻塞/恢复的单元和执行结果都以key作为主键，将此变量放入OnFlightCallRes中 代码 1public class SingleFlight 2{ 3/// &amp;lt;summary&amp;gt; 4/// Keep Key After Execute Call 5/// &amp;lt;/summary&amp;gt; 6private readonly bool _keepKey; 78/// &amp;lt;summary&amp;gt; 9/// dic to store call result 10/// &amp;lt;/summary&amp;gt; 11private readonly Dictionary&amp;lt;string, OnFlightCallRes&amp;gt; _onFlight; 1213/// &amp;lt;summary&amp;gt; 14/// lock 15/// &amp;lt;/summary&amp;gt; 16private readonly ReaderWriterLockSlim _lockSlim; 1718public SingleFlight(bool keepKey) 19{ 20_keepKey = keepKey; 21_onFlight = new Dictionary&amp;lt;string, OnFlightCallRes&amp;gt;(); 22_lockSlim = new ReaderWriterLockSlim(); 23} 2425/// &amp;lt;summary&amp;gt; 26/// Return &amp;lt;paramref name=&amp;#34;callFunc&amp;#34;/&amp;gt; Result 27/// calls from different thread with the same &amp;lt;paramref name=&amp;#34;key&amp;#34;/&amp;gt; will be compressed to one call 28/// &amp;lt;/summary&amp;gt; 29/// &amp;lt;typeparam name=&amp;#34;T&amp;#34;&amp;gt;&amp;lt;/typeparam&amp;gt; 30/// &amp;lt;param name=&amp;#34;key&amp;#34;&amp;gt;&amp;lt;/param&amp;gt; 31/// &amp;lt;param name=&amp;#34;callFunc&amp;#34;&amp;gt;&amp;lt;/param&amp;gt; 32/// &amp;lt;returns&amp;gt;&amp;lt;/returns&amp;gt; 33public T Call&amp;lt;T&amp;gt;(string key, Func&amp;lt;T&amp;gt; callFunc) 34{ 35_lockSlim.</description></item><item><title>Template in C#</title><link>https://ryji.github.io/post/csharp/template_in_csharp/</link><pubDate>Mon, 05 Mar 2018 05:43:58 +0800</pubDate><guid>https://ryji.github.io/post/csharp/template_in_csharp/</guid><description>
引言 泛型（参数化类型），将程序逻辑从具体的类型中分离出来，从而提高代码的复用性。 .Net的System.Collections.Generic命名空间中定义的大多数类型使用了泛型技术，比如List&amp;lt;T&amp;gt;，Stack&amp;lt;T&amp;gt;，Tuple&amp;lt;T1, T2, T3, ...&amp;gt;，SortedList&amp;lt;TKey, TValue&amp;gt;等，另外，委托类型也提供了泛型委托Action和Function。泛型接口定义了一种参数化类型的接口，保障程序的类型安全。
泛型树节点接口 以树的遍历为例，不管树节点的类型和实现是什么，只要知道当前节点的深度和其子节点，就可以进行树的遍历。因此，定义泛型树节点接口ITreeNode&amp;lt;T&amp;gt;。
1public interface ITreeNode&amp;lt;T&amp;gt; where T : class 2{ 3int Depth { get; set; } //深度 4List&amp;lt;T&amp;gt; GetChildren(); //获取子节点 5} 泛型树的约束 在泛型树的定义中添加约束class和ITreeNode&amp;lt;T&amp;gt;，这样，在编译期就可以确保类型安全，用未实现ITreeNode&amp;lt;T&amp;gt;接口的class来实例化Tree&amp;lt;T&amp;gt;时会编译出错。
1public class Tree&amp;lt;T&amp;gt; where T : class, ITreeNode&amp;lt;T&amp;gt; 2{ 3//树根 4public T Root { get; set; } 5//最大深度 6public int MaxDepth { get; set; } 78public void Travel() 9{ 10Travel(Root, MaxDepth); 11} 1213public void Travel(int maxDepth) 14{ 15Debug.Assert(maxDepth &amp;gt;= 0); 16Travel(Root, Math.</description></item></channel></rss>